{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics - Product Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date: 2020/02\n",
    "\n",
    "#### SUMMARY:\n",
    "\n",
    "- This notebook represents the project quality analysis of the date exposed right above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM:\n",
    "\n",
    "##### Semester: YYYY/0X\n",
    "##### Professor: Hilmer Neri\n",
    "\n",
    "##### Members:\n",
    "\n",
    "- Member x\n",
    "- Member y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with data\n",
    "import pandas as pd\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Deal with visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deal with time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace your semester, project name, repository name, and the programming language extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "language = [['fga-eps-mds-2022-1-Capju-User', 'js'],\n",
    "           ['fga-eps-mds-2022-1-Capju-Interface', 'js'],\n",
    "           ['fga-eps-mds-2022-1-Capju-Service', 'js']]\n",
    "\n",
    "repos_language = {}\n",
    "\n",
    "for item in language:\n",
    "    repos_language[f\"{item[0]}\"] = item[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SonarCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path to the folder with all your jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = glob('analytics-raw-data/2022-1-CAPJu/*.json') # add your path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path):\n",
    "    \n",
    "    with open(json_path) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        \n",
    "    return json_obj\n",
    "\n",
    "def create_base_component_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        base_component = read_json(i)\n",
    "\n",
    "        base_component_data = base_component['baseComponent']['measures']\n",
    "\n",
    "        base_component_df = pd.DataFrame(base_component_data)\n",
    "\n",
    "        base_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(base_component_df, ignore_index=True)\n",
    "        \n",
    "    # Replace the UnB semester with yours.\n",
    "    aux_df = df['filename'].str.split(r\"fga-eps-mds-2022.1-(.*?)-(.*?)-(.*?)-(.*?)-v(.*?).json\", expand=True)\n",
    "\n",
    "    df['repository'] = aux_df[2]\n",
    "\n",
    "    df['version'] = aux_df[5]\n",
    "\n",
    "    df = df.sort_values(by=['repository', 'version'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create base component dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/1251919851.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(base_component_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "base_component_df = create_base_component_df(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>bestValue</th>\n",
       "      <th>filename</th>\n",
       "      <th>repository</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>duplicated_lines_density</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>functions</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>security_rating</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>files</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>complexity</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ncloc</td>\n",
       "      <td>1361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>coverage</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>comment_lines_density</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>duplicated_lines_density</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-08-17-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>functions</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fga-eps-mds-2022-1-Capju-Interface-08-17-2022-...</td>\n",
       "      <td>Interface</td>\n",
       "      <td>0.2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       metric value bestValue  \\\n",
       "40   duplicated_lines_density   0.0      True   \n",
       "41                  functions    82       NaN   \n",
       "42            security_rating   1.0      True   \n",
       "43                      files    28       NaN   \n",
       "44                 complexity    97       NaN   \n",
       "45                      ncloc  1361       NaN   \n",
       "46                   coverage   0.0     False   \n",
       "47      comment_lines_density   0.1     False   \n",
       "104  duplicated_lines_density   0.0      True   \n",
       "105                 functions   109       NaN   \n",
       "\n",
       "                                              filename repository version  \n",
       "40   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "41   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "42   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "43   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "44   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "45   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "46   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "47   fga-eps-mds-2022-1-Capju-Interface-07-31-2022-...  Interface   0.1.0  \n",
       "104  fga-eps-mds-2022-1-Capju-Interface-08-17-2022-...  Interface   0.2.0  \n",
       "105  fga-eps-mds-2022-1-Capju-Interface-08-17-2022-...  Interface   0.2.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_component_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_list = ['files',\n",
    "               'functions',\n",
    "               'complexity',\n",
    "               'comment_lines_density',\n",
    "               'duplicated_lines_density',\n",
    "               'coverage',\n",
    "               'ncloc',\n",
    "               'tests',\n",
    "               'test_errors',\n",
    "               'test_failures',\n",
    "               'test_execution_time',\n",
    "               'security_rating']\n",
    "\n",
    "len(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_files_df(df):\n",
    "    \n",
    "    files = df[df['qualifier'] == 'FIL'] \n",
    "    \n",
    "    files = files.dropna(subset=['functions', 'complexity','comment_lines_density', 'duplicated_lines_density', 'coverage' ])\n",
    "    \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dir_df(df):\n",
    "    dirs = df[df[\"qualifier\"] == \"DIR\"]     \n",
    "    \n",
    "    print(\"dirs['tests']=\", dirs[\"tests\"])\n",
    "    newdf = pd.to_numeric(dirs[\"tests\"])\n",
    "    print(\"max_value_index=\", newdf)\n",
    "    \n",
    "    max_value_index = newdf.idxmax()            \n",
    "    return dirs.loc[max_value_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uts_df(df):\n",
    "    dirs = df[df['qualifier'] == 'UTS']     \n",
    "\n",
    "    dirs = dirs.dropna(subset=['test_execution_time'])          \n",
    "    \n",
    "    return dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_per_file(json):\n",
    "    \n",
    "    file_json = []\n",
    "    \n",
    "    for component in json['components']:\n",
    "        \n",
    "        ncloc_value = 0;\n",
    "        \n",
    "        for valores in component['measures']:\n",
    "\n",
    "            if valores['metric'] == 'ncloc':\n",
    "                ncloc_value = float(valores['value'])\n",
    "                break\n",
    "    \n",
    "        if (component['qualifier'] == 'FIL') & (ncloc_value > 0) or (component['qualifier'] == 'DIR') or (component['qualifier'] == 'UTS'):                       \n",
    "            file_json.append(component)\n",
    "\n",
    "    return file_json\n",
    "\n",
    "def generate_file_dataframe_per_release(metric_list, json, language_extension):\n",
    "    \n",
    "    df_columns = metric_list\n",
    "    df = pd.DataFrame(columns = df_columns)\n",
    "    df2 = pd.DataFrame(columns = df_columns)\n",
    "    df3 = pd.DataFrame(columns = df_columns)\n",
    "    \n",
    "    \n",
    "    for file in json:\n",
    "        try:\n",
    "                if file['qualifier'] == 'FIL' and file['language'] == language_extension:\n",
    "                    for measure in file['measures']:\n",
    "                        df.at[file['path'], measure['metric']] = measure['value']\n",
    "\n",
    "                    df['qualifier'] = file['qualifier'] \n",
    "\n",
    "                elif file['qualifier'] == 'UTS':  \n",
    "                    for measure in file['measures']:\n",
    "                        df3.at[file['path'], measure['metric']] = measure['value']\n",
    "\n",
    "                    df3['qualifier'] = file['qualifier'] \n",
    "                elif file['qualifier'] == 'DIR':\n",
    "                    for measure in file['measures']:\n",
    "                        df2.at[file['path'], measure['metric']] = measure['value']\n",
    "                    df2['qualifier'] = file['qualifier'] \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df.reset_index(inplace = True)\n",
    "    df2.reset_index(inplace = True)\n",
    "    df3.reset_index(inplace = True)\n",
    "    df = df.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "    df2 = df2.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "    df3 = df3.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "\n",
    "    dfFinal = pd.concat([df,df2,df3], axis=0)\n",
    "\n",
    "    return dfFinal\n",
    "\n",
    "def create_file_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    dfDir = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        file_component = read_json(i)\n",
    "        \n",
    "        file_component_data = metric_per_file(file_component)\n",
    "                        \n",
    "        file_name = os.path.basename(i)\n",
    "\n",
    "        file_repository = re.split(r'-(\\d+-\\d+-\\d+-\\d+-\\d+-\\d+)-v(.*?).json', file_name)[0]\n",
    "\n",
    "        file_language = repos_language[f\"{file_repository}\"]\n",
    "\n",
    "        file_component_df = generate_file_dataframe_per_release(metric_list, file_component_data, language_extension = file_language)\n",
    "        \n",
    "        file_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(file_component_df, ignore_index=True)\n",
    "        \n",
    "    # Replace the UnB semester with yours.\n",
    "    \n",
    "    aux_df = df['filename'].str.split(r\"-(\\d+-\\d+-\\d+-\\d+-\\d+-\\d+)-v(.*?).json\", expand=True)\n",
    "\n",
    "    df['repository'] = aux_df[0]\n",
    "\n",
    "    df['version'] = aux_df[2]\n",
    "\n",
    "    df = df.sort_values(by=['version'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n",
      "/tmp/ipykernel_235731/3038128456.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(file_component_df, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fga-eps-mds-2022-1-Capju-Interface',\n",
       "       'fga-eps-mds-2022-1-Capju-Service',\n",
       "       'fga-eps-mds-2022-1-Capju-User'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_component_df = create_file_df(jsons)\n",
    "file_component_df.repository.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " file_component_df = file_component_df.dropna(subset=['functions', 'complexity','comment_lines_density', 'duplicated_lines_density', 'coverage' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #### Create dataframe per repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example. You must replace repo1, repo1,..., for your repository's names\n",
    "\n",
    "repo1_df = file_component_df[file_component_df['repository'] == 'fga-eps-mds-2022-1-Capju-Service']\n",
    "repo2_df = file_component_df[file_component_df['repository'] == 'fga-eps-mds-2022-1-Capju-Interface']\n",
    "repo3_df = file_component_df[file_component_df['repository'] == 'fga-eps-mds-2022-1-Capju-User']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _ncloc(df):\n",
    "    ncloc = 0\n",
    "    for each in df['ncloc']:\n",
    "        n = 0\n",
    "        # try to cast the current ncloc value to int, if the value is NaN/Null, consider it as zero.\n",
    "        try:\n",
    "            n = int(each)\n",
    "        except ValueError:\n",
    "            n = 0\n",
    "        ncloc += n\n",
    "\n",
    "    return ncloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure calculations according Q-Rapids quality model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Aspect - Maintainability\n",
    "## Factor - Code Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1(df):\n",
    "\n",
    "    files_df = get_files_df(df)\n",
    "    \n",
    "    density_non_complex_files = len(files_df[(files_df['complexity'].astype(float) /\n",
    "                                              files_df['functions'].astype(float)) < 10]) / len(files_df)\n",
    "    \n",
    "    return density_non_complex_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2(df):\n",
    "\n",
    "    files_df = get_files_df(df)\n",
    "    \n",
    "    density_comment_files = len(files_df[(files_df['comment_lines_density'].astype(float) > 10) &\n",
    "                                         (files_df['comment_lines_density'].astype(float) < 30)]) / len(files_df)\n",
    "    \n",
    "    return density_comment_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DUPLICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m3(df):\n",
    "\n",
    "    files_df = get_files_df(df)\n",
    "    \n",
    "    duplication = len(files_df[(files_df['duplicated_lines_density'].astype(float) < 5)])/len(files_df)\n",
    "    \n",
    "    return duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Aspect - Reliability\n",
    "## Factor - Testing Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Passed tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def m4(df):\n",
    "\n",
    "    dir_df = get_dir_df(df)\n",
    "\n",
    "    passed_tests = (float(dir_df['tests']) - (float(dir_df['test_errors']) + float(dir_df['test_failures']))) /\\\n",
    "                   float(dir_df['tests'])\n",
    "\n",
    "    return passed_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fast test builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def m5(df):\n",
    "\n",
    "    dir_df = get_uts_df(df)\n",
    "    \n",
    "    density_fast_test_builds = len(dir_df[(dir_df['test_execution_time'].astype(float)) < 300000]) /\\\n",
    "                               len(dir_df['test_execution_time'].astype(float))\n",
    "    return density_fast_test_builds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def m6(df):\n",
    "\n",
    "    files_df = get_files_df(df)\n",
    "\n",
    "    density_test_coverage = len(files_df[(files_df['coverage'].astype(float) > 60)]) / len(files_df)\n",
    "\n",
    "    return density_test_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate m1, m2, m3, m4, m5 and m6 for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_df(df):\n",
    "    \n",
    "    version_vec = df['version'].unique()\n",
    "    \n",
    "    m1_list = []\n",
    "    m2_list = []\n",
    "    m3_list = []\n",
    "    m4_list = []\n",
    "    m5_list = []\n",
    "    m6_list = []\n",
    "\n",
    "    ncloc_list = []\n",
    "    repository_list = []\n",
    "    version_list = []\n",
    "    \n",
    "    for version in version_vec:\n",
    "\n",
    "        version_df = df[df['version'] == version]\n",
    "\n",
    "        m1_list.append(m1(version_df))\n",
    "        m2_list.append(m2(version_df))\n",
    "        m3_list.append(m3(version_df))\n",
    "        m4_list.append(m4(version_df))\n",
    "        m5_list.append(m5(version_df))\n",
    "        m6_list.append(m6(version_df))\n",
    "\n",
    "        ncloc_list.append(_ncloc(version_df))\n",
    "        repository_list.append(version_df['repository'].iloc[0])\n",
    "        version_list.append(version)\n",
    "        \n",
    "    metrics_df = pd.DataFrame({'m1': m1_list,\n",
    "                               'm2': m2_list,\n",
    "                               'm3': m3_list,\n",
    "                               'm4': m4_list,\n",
    "                               'm5': m5_list,\n",
    "                               'm6': m6_list,\n",
    "                               'repository': repository_list, \n",
    "                               'version': version_list,\n",
    "                               'ncloc': ncloc_list})\n",
    "        \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs['tests']= 422    NaN\n",
      "421    NaN\n",
      "420    NaN\n",
      "419    NaN\n",
      "417    NaN\n",
      "418    NaN\n",
      "535    NaN\n",
      "536    NaN\n",
      "537    NaN\n",
      "538    NaN\n",
      "539    NaN\n",
      "540    NaN\n",
      "Name: tests, dtype: object\n",
      "max_value_index= 422   NaN\n",
      "421   NaN\n",
      "420   NaN\n",
      "419   NaN\n",
      "417   NaN\n",
      "418   NaN\n",
      "535   NaN\n",
      "536   NaN\n",
      "537   NaN\n",
      "538   NaN\n",
      "539   NaN\n",
      "540   NaN\n",
      "Name: tests, dtype: float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:41\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: nan",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m repo1 \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_metrics_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo1_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m repo2 \u001b[38;5;241m=\u001b[39m create_metrics_df(repo2_df)\n\u001b[1;32m      3\u001b[0m repo3 \u001b[38;5;241m=\u001b[39m create_metrics_df(repo3_df)\n",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36mcreate_metrics_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m m2_list\u001b[38;5;241m.\u001b[39mappend(m2(version_df))\n\u001b[1;32m     22\u001b[0m m3_list\u001b[38;5;241m.\u001b[39mappend(m3(version_df))\n\u001b[0;32m---> 23\u001b[0m m4_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mm4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion_df\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     24\u001b[0m m5_list\u001b[38;5;241m.\u001b[39mappend(m5(version_df))\n\u001b[1;32m     25\u001b[0m m6_list\u001b[38;5;241m.\u001b[39mappend(m6(version_df))\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mm4\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mm4\u001b[39m(df):\n\u001b[0;32m----> 3\u001b[0m     dir_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_dir_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     passed_tests \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mfloat\u001b[39m(dir_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtests\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m-\u001b[39m (\u001b[38;5;28mfloat\u001b[39m(dir_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_errors\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mfloat\u001b[39m(dir_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_failures\u001b[39m\u001b[38;5;124m'\u001b[39m]))) \u001b[38;5;241m/\u001b[39m\\\n\u001b[1;32m      6\u001b[0m                    \u001b[38;5;28mfloat\u001b[39m(dir_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtests\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m passed_tests\n",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36mget_dir_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_value_index=\u001b[39m\u001b[38;5;124m\"\u001b[39m, newdf)\n\u001b[1;32m      8\u001b[0m max_value_index \u001b[38;5;241m=\u001b[39m newdf\u001b[38;5;241m.\u001b[39midxmax()            \n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdirs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmax_value_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1202\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:3864\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3862\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   3863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3864\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3866\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   3867\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "repo1 = create_metrics_df(repo1_df)\n",
    "repo2 = create_metrics_df(repo2_df)\n",
    "repo3 = create_metrics_df(repo3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "- You must do this for each of your repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(repo1['m1'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo1['m2'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo1['m3'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo1['m4'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo1['m5'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo1['m6'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(repo2['m1'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo2['m2'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo2['m3'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo2['m4'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo2['m5'], linewidth=3, marker='o', markersize=10)\n",
    "plt.plot(repo2['m6'], linewidth=3, marker='o', markersize=10)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality factor and aspect aggregation\n",
    "\n",
    "- You must do this for each of your repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psc1 = 1\n",
    "psc2 = 1\n",
    "pc1 = 0.5\n",
    "pc2 = 0.5\n",
    "pm1 = 0.33\n",
    "pm2 = 0.33\n",
    "pm3 = 0.33\n",
    "pm4 = 0.25\n",
    "pm5 = 0.25\n",
    "pm6 = 0.5\n",
    "\n",
    "repo1['code_quality'] = ((repo1['m1']*pm1) + (repo1['m2']*pm2) + (repo1['m3']*pm3)) * psc1\n",
    "repo2['code_quality'] = ((repo2['m1']*pm1) + (repo2['m2']*pm2) + (repo2['m3']*pm3)) * psc1\n",
    "repo3['code_quality'] = ((repo3['m1']*pm1) + (repo3['m2']*pm2) + (repo3['m3']*pm3)) * psc1\n",
    "\n",
    "repo1['testing_status'] = ((repo1['m4']*pm4) + (repo1['m5']*pm5) + (repo1['m6']*pm6)) * psc2\n",
    "repo2['testing_status'] = ((repo2['m4']*pm4) + (repo2['m5']*pm5) + (repo2['m6']*pm6)) * psc2\n",
    "repo3['testing_status'] = ((repo3['m4']*pm4) + (repo3['m5']*pm5) + (repo3['m6']*pm6)) * psc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(repo1['code_quality'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo2['code_quality'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo3['code_quality'], linewidth=3, marker='o', markersize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(repo1['testing_status'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo2['testing_status'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo3['testing_status'], linewidth=3, marker='o', markersize=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo1['Maintainability'] = repo1['code_quality'] * pc1\n",
    "repo1['Reliability'] = repo1['testing_status'] * pc2\n",
    "repo1['total'] = repo1['Maintainability'] + repo1['Reliability']\n",
    "\n",
    "repo2['Maintainability'] = repo2['code_quality'] * pc1\n",
    "repo2['Reliability'] = repo2['testing_status'] * pc2\n",
    "repo2['total'] = repo2['Maintainability'] + repo2['Reliability']\n",
    "\n",
    "repo3['Maintainability'] = repo3['code_quality'] * pc1\n",
    "repo3['Reliability'] = repo3['testing_status'] * pc2\n",
    "repo3['total'] = repo3['Maintainability'] + repo3['Reliability']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(repo1['Maintainability'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo1['Reliability'], linewidth=3, marker='*', markersize=5)\n",
    "plt.plot(repo1['total'], linewidth=3, marker='X', markersize=5)\n",
    "\n",
    "plt.ylim(0.1,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "repo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(repo2['Maintainability'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo2['Reliability'], linewidth=3, marker='*', markersize=5)\n",
    "plt.plot(repo2['total'], linewidth=3, marker='X', markersize=5)\n",
    "\n",
    "plt.ylim(0.1,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(repo3['Maintainability'], linewidth=3, marker='o', markersize=5)\n",
    "plt.plot(repo3['Reliability'], linewidth=3, marker='*', markersize=5)\n",
    "plt.plot(repo3['total'], linewidth=3, marker='X', markersize=5)\n",
    "\n",
    "plt.ylim(0.1,1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You must do the total plot and the statics analysis for the repository with more versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Building descriptive statistics dataframe. You must replace YourRepoName for your repository name with more product versions.\n",
    "\n",
    "metrics_df = pd.concat([repo1, repo2, repo3], ignore_index=True)\n",
    "\n",
    "more_versions_repo = metrics_df[metrics_df['repository'] == 'fga-eps-mds-2022-1-Capju-Interface']\n",
    "\n",
    "def get_characteristc_stats(repo_series):\n",
    "    return {\n",
    "        'mean': repo_series.mean(),\n",
    "        'mode': repo_series.mode(),\n",
    "        'median': repo_series.median(),\n",
    "        'std': repo_series.std(),\n",
    "        'var': repo_series.var(),\n",
    "        'min': repo_series.min(),\n",
    "        'max': repo_series.max()\n",
    "    }\n",
    "\n",
    "maintainability_stats = pd.DataFrame(get_characteristc_stats(more_versions_repo[\"Maintainability\"]),\n",
    "                                     columns=['mean', 'mode', 'median', 'std', 'var', 'min', 'max'])\n",
    "\n",
    "reliability_stats = pd.DataFrame(get_characteristc_stats(more_versions_repo[\"Reliability\"]),\n",
    "                                 columns=['mean', 'mode', 'median', 'std', 'var', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(maintainability_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(reliability_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the aggregated quality characteristic indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# boxplot\n",
    "plt.boxplot([more_versions_repo['Maintainability'], more_versions_repo['Reliability']],\n",
    "labels=['Maintainability', 'Reliability'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the aggregated repository quality indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(more_versions_repo['total'], linewidth=3, marker='o', markersize=5)\n",
    "\n",
    "plt.ylim(.1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATE FORMAT: MM-DD-YYYY-HH:MM:SS\n",
    "currentDateTime = datetime.datetime.now().strftime(\"%m-%d-%Y-%H:%M:%S\")\n",
    "\n",
    "metrics_df.to_excel('data/fga-eps-mds-2022-1-Capju-Interface-{}.xlsx'.format(currentDateTime), index = False)\n",
    "\n",
    "metrics_df.to_csv('data/fga-eps-mds-2022-1-Capju-Interface-{}.csv'.format(currentDateTime), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
